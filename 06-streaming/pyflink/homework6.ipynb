{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e63db8-6221-4efa-ab52-a833779ef52f",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "In this homework, we're going to learn about streaming with PyFlink.\n",
    "\n",
    "Instead of Kafka, we will use Red Panda, which is a drop-in\n",
    "replacement for Kafka. It implements the same interface, \n",
    "so we can use the Kafka library for Python for communicating\n",
    "with it, as well as use the Kafka connector in PyFlink.\n",
    "\n",
    "For this homework we will be using the Taxi data:\n",
    "- Green 2019-10 data from [here](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz)\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "We need:\n",
    "\n",
    "- Red Panda\n",
    "- Flink Job Manager\n",
    "- Flink Task Manager\n",
    "- Postgres\n",
    "\n",
    "It's the same setup as in the [pyflink module](../../../06-streaming/pyflink/), so go there and start docker-compose:\n",
    "\n",
    "```bash\n",
    "cd ../../../06-streaming/pyflink/\n",
    "docker-compose up\n",
    "```\n",
    "\n",
    "(Add `-d` if you want to run in detached mode)\n",
    "\n",
    "Visit http://localhost:8081 to see the Flink Job Manager\n",
    "\n",
    "Connect to Postgres with pgcli, pg-admin, [DBeaver](https://dbeaver.io/) or any other tool.\n",
    "\n",
    "The connection credentials are:\n",
    "\n",
    "- Username `postgres`\n",
    "- Password `postgres`\n",
    "- Database `postgres`\n",
    "- Host `localhost`\n",
    "- Port `5432`\n",
    "\n",
    "With pgcli or dBeaver, you'll need to run this to connect:\n",
    "\n",
    "```bash\n",
    "pgcli -h localhost -p 5432 -u postgres -d postgres\n",
    "```\n",
    "\n",
    "Run these query to create the Postgres landing zone for the first events and windows:\n",
    "\n",
    "```sql \n",
    "CREATE TABLE processed_events (\n",
    "    test_data INTEGER,\n",
    "    event_timestamp TIMESTAMP\n",
    ");\n",
    "\n",
    "CREATE TABLE processed_events_aggregated (\n",
    "    event_hour TIMESTAMP,\n",
    "    test_data INTEGER,\n",
    "    num_hits INTEGER \n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e619285-b792-4fc6-be14-4e9cafa42788",
   "metadata": {},
   "source": [
    "## Question 1: Redpanda version\n",
    "\n",
    "Now let's find out the version of redpandas. \n",
    "\n",
    "For that, check the output of the command `rpk help` _inside the container_. The name of the container is `redpanda-1`.\n",
    "\n",
    "Find out what you need to execute based on the `help` output.\n",
    "\n",
    "What's the version, based on the output of the command you executed? (copy the entire version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341022eb-25f1-44d2-9a14-003bdd43e81e",
   "metadata": {},
   "source": [
    "## Answer 1: Redpanda version\n",
    "`rpk help`\n",
    "\n",
    "`rpk version`\n",
    "\n",
    "Redpanda Cluster\n",
    "  node-1  v24.2.18 - f9a22d443087b824803638623d6b7492ec8221f9\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a77667f-6ce7-4834-aaf0-0536ccb5c0a5",
   "metadata": {},
   "source": [
    "## Question 2. Creating a topic\n",
    "\n",
    "Before we can send data to the redpanda server, we\n",
    "need to create a topic. We do it also with the `rpk`\n",
    "command we used previously for figuring out the version of \n",
    "redpandas.\n",
    "\n",
    "Read the output of `help` and based on it, create a topic with name `green-trips` \n",
    "\n",
    "What's the output of the command for creating a topic? Include the entire output in your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b8794e-9713-4e46-ad1d-2a9817530b07",
   "metadata": {},
   "source": [
    "## Answer 2. Creating a topic\n",
    "`$ rpk topic create green-trips`                                                               \n",
    "TOPIC        STATUS\n",
    "green-trips  OK\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e2e89f-c1f9-4976-924c-be8b8cebca4f",
   "metadata": {},
   "source": [
    "## Question 3. Connecting to the Kafka server\n",
    "\n",
    "We need to make sure we can connect to the server, so\n",
    "later we can send some data to its topics\n",
    "\n",
    "First, let's install the kafka connector (up to you if you\n",
    "want to have a separate virtual environment for that)\n",
    "\n",
    "```bash\n",
    "pip install kafka-python\n",
    "```\n",
    "\n",
    "You can start a jupyter notebook in your solution folder or\n",
    "create a script\n",
    "\n",
    "Let's try to connect to our server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ece1b96-ebb6-4457-8841-45399ea72ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "def json_serializer(data):\n",
    "    return json.dumps(data).encode('utf-8')\n",
    "\n",
    "server = 'localhost:9092'\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=[server],\n",
    "    value_serializer=json_serializer\n",
    ")\n",
    "\n",
    "producer.bootstrap_connected()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9732b875-022e-4e81-90ea-5757955193b4",
   "metadata": {},
   "source": [
    "\n",
    "Provided that you can connect to the server, what's the output\n",
    "of the last command?\n",
    "\n",
    "## Answer 3:\n",
    "True\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1025ae4-2b8a-44e8-9897-3ff762380fc6",
   "metadata": {},
   "source": [
    "## Question 4: Sending the Trip Data\n",
    "\n",
    "Now we need to send the data to the `green-trips` topic\n",
    "Read the data, and keep only these columns:\n",
    "\n",
    "* `'lpep_pickup_datetime',`\n",
    "* `'lpep_dropoff_datetime',`\n",
    "* `'PULocationID',`\n",
    "* `'DOLocationID',`\n",
    "* `'passenger_count',`\n",
    "* `'trip_distance',`\n",
    "* `'tip_amount'`\n",
    "\n",
    "Now send all the data using this code:\n",
    "\n",
    "```python\n",
    "producer.send(topic_name, value=message)\n",
    "```\n",
    "\n",
    "For each row (`message`) in the dataset. In this case, `message`\n",
    "is a dictionary.\n",
    "\n",
    "After sending all the messages, flush the data:\n",
    "\n",
    "```python\n",
    "producer.flush()\n",
    "```\n",
    "\n",
    "Use `from time import time` to see the total time \n",
    "\n",
    "```python\n",
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# ... your code\n",
    "\n",
    "t1 = time()\n",
    "took = t1 - t0\n",
    "```\n",
    "\n",
    "How much time did it take to send the entire dataset and flush? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "490b04f7-ac3b-4f23-8f39-4374416fedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4350f927-508a-4766-94fe-956d1c41a1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 4:\n",
      "Time taken:28.012919187545776 seconds to send 476386 messages\n"
     ]
    }
   ],
   "source": [
    "chunksize = 10000\n",
    "columns_to_keep = [\n",
    "    'lpep_pickup_datetime',\n",
    "    'lpep_dropoff_datetime',\n",
    "    'PULocationID',\n",
    "    'DOLocationID',\n",
    "    'passenger_count',\n",
    "    'trip_distance',\n",
    "    'tip_amount'\n",
    "]\n",
    "topic_name = 'green-trips'\n",
    "t0 = time()\n",
    "msg_counter = 0\n",
    "for chunk in pd.read_csv(\n",
    "    '/Users/zharauai/de-zoomcamp-2025/06-streaming/pyflink/data_for_hw6/green_tripdata_2019-10.csv.gz', \n",
    "    compression='gzip',\n",
    "    chunksize=chunksize,\n",
    "    low_memory=False\n",
    "    ):\n",
    "    chunk = chunk[columns_to_keep]\n",
    "\n",
    "    for _, row in chunk.iterrows():\n",
    "        msg_counter += 1\n",
    "        message = row.to_dict()\n",
    "        producer.send(topic_name, value=message)\n",
    "    producer.flush()\n",
    "    \n",
    "t1 = time()\n",
    "took = t1 - t0\n",
    "\n",
    "print('Answer 4:')\n",
    "print(f'Time taken:{took} seconds to send {msg_counter} messages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9236d7-3ed8-4a37-bec0-db9db2737a90",
   "metadata": {},
   "source": [
    "## Answer 4:\n",
    "First attempt: \\\n",
    "Time taken:27.428909063339233 seconds to send 476386 messages\n",
    "\n",
    "...\n",
    "\n",
    "Fourth attempt: \\\n",
    "Time taken:27.71467399597168 seconds to send 476386 messages\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360379d-3421-4e16-981b-30b30fde6b8d",
   "metadata": {},
   "source": [
    "## Question 5: Build a Sessionization Window (2 points)\n",
    "\n",
    "Now we have the data in the Kafka stream. It's time to process it.\n",
    "\n",
    "* Copy `aggregation_job.py` and rename it to `session_job.py`\n",
    "* Have it read from `green-trips` fixing the schema\n",
    "* Use a [session window](https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/operators/windows/) with a gap of 5 minutes\n",
    "* Use `lpep_dropoff_datetime` time as your watermark with a 5 second tolerance\n",
    "* Which pickup and drop off locations have the longest unbroken streak of taxi trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "505e7695-be42-4a46-a5ba-feaaf4ece11a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'py4j'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatastream\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StreamExecutionEnvironment\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EnvironmentSettings, DataTypes, TableEnvironment, StreamTableEnvironment\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwatermark_strategy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WatermarkStrategy\n",
      "File \u001b[0;32m~/de-zoomcamp-2025/06-streaming/venv_streaming/lib/python3.10/site-packages/pyflink/datastream/__init__.py:262\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#  Licensed to the Apache Software Foundation (ASF) under one\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#  or more contributor license agreements.  See the NOTICE file\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03mEntry point classes of Flink DataStream API:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m      Tag with a name and type for identifying side output of an operator\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatastream\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CheckpointConfig, ExternalizedCheckpointCleanup\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatastream\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing_mode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CheckpointingMode\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatastream\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_stream\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataStream, KeyedStream, WindowedStream, \\\n\u001b[1;32m    265\u001b[0m     ConnectedStreams, DataStreamSink, BroadcastStream, BroadcastConnectedStream\n",
      "File \u001b[0;32m~/de-zoomcamp-2025/06-streaming/venv_streaming/lib/python3.10/site-packages/pyflink/datastream/checkpoint_config.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Duration\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatastream\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint_storage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CheckpointStorage, _from_j_checkpoint_storage\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatastream\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing_mode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CheckpointingMode\n",
      "File \u001b[0;32m~/de-zoomcamp-2025/06-streaming/venv_streaming/lib/python3.10/site-packages/pyflink/common/__init__.py:51\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#  Licensed to the Apache Software Foundation (ASF) under one\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#  or more contributor license agreements.  See the NOTICE file\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03mCommon classes used by both Flink DataStream API and Table API:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m      :class:`~SimpleStringSchema` for more details.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompletable_future\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CompletableFuture\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_options\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConfigOption, ConfigOptions\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Configuration\n",
      "File \u001b[0;32m~/de-zoomcamp-2025/06-streaming/venv_streaming/lib/python3.10/site-packages/pyflink/common/completable_future.py:19\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#  Licensed to the Apache Software Foundation (ASF) under one\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#  or more contributor license agreements.  See the NOTICE file\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpy4j\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotocol\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyflink\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_py4j_exception\n\u001b[1;32m     23\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompletableFuture\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'py4j'"
     ]
    }
   ],
   "source": [
    "# session_job.py\n",
    "from pyflink.datastream import StreamExecutionEnvironment\n",
    "from pyflink.table import EnvironmentSettings, DataTypes, TableEnvironment, StreamTableEnvironment\n",
    "from pyflink.common.watermark_strategy import WatermarkStrategy\n",
    "from pyflink.common.time import Duration\n",
    "\n",
    "def create_events_aggregated_sink(t_env):\n",
    "    table_name = 'processed_events_aggregated'\n",
    "    sink_ddl = f\"\"\"\n",
    "        CREATE TABLE {table_name} (\n",
    "            event_hour TIMESTAMP(3),\n",
    "            PULocationID INT,\n",
    "            DOLocationID INT,\n",
    "            num_hits BIGINT,\n",
    "            PRIMARY KEY (event_hour, PULocationID, DOLocationID) NOT ENFORCED\n",
    "        ) WITH (\n",
    "            'connector' = 'jdbc',\n",
    "            'url' = 'jdbc:postgresql://postgres:5432/postgres',\n",
    "            'table-name' = '{table_name}',\n",
    "            'username' = 'postgres',\n",
    "            'password' = 'postgres',\n",
    "            'driver' = 'org.postgresql.Driver'\n",
    "        );\n",
    "        \"\"\"\n",
    "    t_env.execute_sql(sink_ddl)\n",
    "    return table_name\n",
    "\n",
    "def create_events_source_kafka(t_env):\n",
    "    table_name = \"events\"\n",
    "    source_ddl = f\"\"\"\n",
    "        CREATE TABLE {table_name} (\n",
    "            lpep_pickup_datetime TIMESTAMP(3),\n",
    "            lpep_dropoff_datetime TIMESTAMP(3),\n",
    "            PULocationID INT,\n",
    "            DOLocationID INT,\n",
    "            passenger_count INT,\n",
    "            trip_distance DOUBLE,\n",
    "            tip_amount DOUBLE,\n",
    "            event_watermark AS lpep_dropoff_datetime,\n",
    "            WATERMARK FOR event_watermark as event_watermark - INTERVAL '5' SECOND\n",
    "        ) WITH (\n",
    "            'connector' = 'kafka',\n",
    "            'properties.bootstrap.servers' = 'redpanda-1:29092',\n",
    "            'topic' = 'green-trips',\n",
    "            'scan.startup.mode' = 'earliest-offset',\n",
    "            'properties.auto.offset.reset' = 'earliest',\n",
    "            'format' = 'json'\n",
    "        );\n",
    "        \"\"\"\n",
    "    t_env.execute_sql(source_ddl)\n",
    "    return table_name\n",
    "\n",
    "\n",
    "def log_aggregation():\n",
    "    # Set up the execution environment\n",
    "    env = StreamExecutionEnvironment.get_execution_environment()\n",
    "    env.enable_checkpointing(10 * 1000)\n",
    "    env.set_parallelism(1)\n",
    "\n",
    "    # Set up the table environment\n",
    "    settings = EnvironmentSettings.new_instance().in_streaming_mode().build()\n",
    "    t_env = StreamTableEnvironment.create(env, environment_settings=settings)\n",
    "\n",
    "    try:\n",
    "        # Create Kafka table\n",
    "        source_table = create_events_source_kafka(t_env)\n",
    "        aggregated_table = create_events_aggregated_sink(t_env)\n",
    "\n",
    "        t_env.execute_sql(f\"\"\"\n",
    "        INSERT INTO {aggregated_table}\n",
    "        SELECT\n",
    "            window_start as event_hour,\n",
    "            PULocationID,\n",
    "            DOLocationID,\n",
    "            COUNT(*) AS num_hits\n",
    "        FROM TABLE(\n",
    "            TUMBLE(\n",
    "                TABLE {source_table}, \n",
    "                DESCRIPTOR(event_watermark), \n",
    "                INTERVAL '5' MINUTE\n",
    "            )\n",
    "        )\n",
    "        GROUP BY window_start, PULocationID, DOLocationID;\n",
    "        \"\"\").wait()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Writing records from Kafka to JDBC failed:\", str(e))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    log_aggregation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2165263a-64d0-4c84-89b0-0f14b5462c56",
   "metadata": {},
   "source": [
    "Rebuild docker-copose and run:\n",
    "```\n",
    "docker compose exec jobmanager ./bin/flink run -py /opt/src/job/session_job.py --pyFiles /opt/src -d\n",
    "```\n",
    "\n",
    "## Answer 5:\n",
    "PULocationID - 75 - East Harlem South\n",
    "DOLocationID - 74 - East Harlem North\n",
    "longest_unbroken_streak - 142\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b7a8c-dc9e-4e93-ab04-85cea0b4ef1f",
   "metadata": {},
   "source": [
    "## Submitting the solutions\n",
    "\n",
    "- Form for submitting: https://courses.datatalks.club/de-zoomcamp-2025/homework/hw6\n",
    "- Deadline: See the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7a363-8e78-406d-ae3d-4f90e6ac77cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_streaming)",
   "language": "python",
   "name": "venv_streaming"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
